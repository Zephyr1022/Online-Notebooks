### 拆分：一个理解问题的基准

理解自然语言问题需要有能力将问题分解成计算其答案的必要步骤。



在这项工作中，我们引入了问题分解意义表示(QDMR)。



QDMR构成回答问题所必需的、通过自然语言表达的有序步骤列表。



我们开发了一个众包管道，表明高质量的QDMR可以被大规模标注，并发布包含超过83K对问题及其QDMR的BREAK数据集。



我们通过证明QDMR的有效性：

(A)它可以用来改进HotpotQA数据集上的开放领域问答；

(B)它可以确定性地转换为伪SQL形式语言，这可以减轻语义分析应用中的标注。

最后，我们使用BREAK来训练一个序列到序列的模型，将解析问题的模型复制到QDMR结构中，并表明它的性能大大优于几条自然基线。

```
论文地址

https://arxiv.org/abs/2001.11770v1

下载地址

https://arxiv.org/pdf/2001.11770v1.pdf

全部源码

https://github.com/allenai/Break

https://github.com/tomerwolgithub/Break

https://github.com/allenai/break-evaluator
```



### 开放领域问答通过问题重写进行对话

摘要：我们介绍了一个新的会话上下文中问题重写的数据集(QReCC)，它包含了14K个会话和81K个问答对。QReCC的任务是在1000万个网页(分成5400万段)集合中找到会话问题的答案。同一对话中的问题答案可以分布在几个网页上。QReCC提供了注释，允许我们训练和评估端到端会话问答(QA)任务所需的问题重写、段落检索和阅读理解等各个子任务。我们报告了一个强大的基线方法的有效性，该方法结合了最先进的问题重写模型和开放领域QA的好胜模型。我们的结果为QReCC数据集设置了第一个基线，F1为19.07，而人类的上限为74.47，这表明设置的难度和很大的改进空间。



### 面向开放领域问答的知识引导文本检索与阅读

摘要：我们介绍了一种开放领域问答(QA)的方法，它检索和读取段落图，其中顶点是文本的段落，边表示来自外部知识库或在同一文章中共现的关系。我们的目标是通过使用知识引导检索来查找比文本匹配方法更相关的段落来提高覆盖率，并通过允许更好地知识引导跨相关段落的信息融合来提高准确性。我们的图检索方法通过遍历知识库的图结构来扩展一组种子关键字检索的文章。我们的读者扩展了基于Bert的体系结构，并通过传播相关段落及其关系的信息来更新段落表示，而不是孤立地阅读每一段。在WebQuestions、Natural Questions和TriviaQA三个开放领域QA数据集上的实验表明，与非图基线相比，性能提高了2-11%。我们的方法在每种情况下都能赶上或超过最先进的水平，而无需使用昂贵的端到端培训体系。https://xueshu.qukaa.com/5231_2019_11.html



### 知识辅助的开放领域问答

https://xueshu.qukaa.com/19719_2020_06.html

摘要：开放领域问答旨在从大量文档中找到问题的答案，

尽管许多单文档机理解模型已经取得了很好的性能，

但由于文档检索和答案重排仍然不尽如人意，开放领域问答系统仍有很大的改进空间。

包含正确答案的黄金文档可能不会被检索组件正确评分，

并且已经提取的正确答案可能被重新排序组件错误地排在其他候选答案之后。

其中一个原因来自独立原则，其中每个候选文档(或答案)独立评分，而不考虑其与其他文档(或答案)的关系。

在这项工作中，我们提出了一种知识辅助的开放领域问答(KAQA)方法，旨在通过考虑问题与文档之间的关系(称为问题-文档图)和候选文档之间的关系(称为文档-文档图)来改进相关文档检索和**候选答案重排序**。

这些图是使用来自外部知识资源的知识**三元组**构建的。

在文档检索期间，通过考虑候选文档与问题和其他文档的关系来对候选文档进行评分。在答案重新排序过程中，候选答案不仅使用它自己的上下文，而且还使用来自其他文档的线索进行重新排序。实验结果表明，该方法改善了文档检索和答案重排，从而提高了开放领域问答系统的整体性能。



```
论文地址

https://arxiv.org/abs/2006.05244v1

下载地址

https://arxiv.org/pdf/2006.05244v1.pdf

全部源码

https://github.com/wmaucla/neo4j_cheatsheet
```





