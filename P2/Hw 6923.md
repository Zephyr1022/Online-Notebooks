From Nihar Bendre to Everyone: (5:06 AM)



From Nihar Bendre to Everyone: (5:06 AM)



From Nihar Bendre to Everyone: (5:06 AM)



Did anyone face any issues when accessing the recorded sessions ? 



Did anyone face any issues when accessing the recorded sessions ? 





### ISLR - Statistical Learning (Ch. 2) - Exercise Solutions

https://www.kaggle.com/lmorgan95/islr-statistical-learning-ch-2-solutions

### ISLR - Classification (Ch. 4) - Exercise Solutions

https://www.kaggle.com/lmorgan95/islr-classification-ch-4-solutions/log

### ISLR - Linear Regression (Ch. 3) - Exercise Solutions

https://www.kaggle.com/lmorgan95/islr-linear-regression-ch-3-solutions

---
title: "hw2"
author: "Xingmeng Zhao"
date: "9/10/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Chapter 2
## 2.1
# For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.
# a The sample size n is extremely large, and the number of predictors p is small.
Better. Because large number of observations make a flexible method capture more complex relationships without a high chance of overfitting
# b The number of predictors p is extremely large, and the number of observations n is small.
Worse. Due to in high dimension of predictors and low dimension of observation data, flexible methods are more risk  of overfitting than inflexible method.
# c The relationship between the predictors and response is highly non-linear.
Better. a flexible method would be better to capture non-linear relationships than inflexible method.
# d The variance of the error terms, i.e. σ2 = Var(ε), is extremely high.
Worse. A flexible method maybe fit the noise in the error terms and increase variance.

## 2.2 
# Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.

# a We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO 
regression problem, Inference  
Regression because response variable CEO salary is continuous, and Inference because they are interested in understanding which factors affect CEO i.e. relationship.
n = 500
p = 3

# b We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.
Classification, prediction 
respose variable are binary and they want to know whether launching a new product will be a success or a failure. 
n = 20
p = 13 

#c We are interesting in predicting the % change in the US dollar in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the dollar, the % change in the US market, the % change in the British market, and the % change in the German market.
regression, prediction
Due to they are interesting in predicting the % change in the US dollar in relation to the weekly changes in the world stock markets.
n = 52
p = 3

## 2.3 We now revisit the bias-variance decomposition.
# a Provide a sketch of typical (squared) bias, variance, training er- ror, test error, and Bayes (or irreducible) error curves, on a sin- gle plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one.














# b Explain why each of the five curves has the shape displayed in part (a).
1, The Bayes-error is constant because it is particular from the dataset and does not alter by modelling features.
2, The training error just decreases as the level of flexibility increases and the function overfits the data, at the end the error assumes a minimum constant value.
3, The test error begins decreasing until a mark level where flexibility starts to overfit the training data (following its noise) and the error starts to increase.
4, The Bias just decreases as the levels of flexibility creates a more complex function, which represents better the real-problem.
5, The Variance starts to increase slowly, after with higher levels of flexibility, the function become less robust and the variance value increases rapidly.

## 2.10 This exercise involves the Boston housing data set.
# (a) To begin, load in the Boston data set. The Boston data set is part of the MASS library in R.
# How many rows are in this data set? How many columns? What do the rows and columns represent?
There are 506 rows and 14 columns
Rows present observation data and columns present variables. 

```{r}
library(MASS)
# Now the data set is contained in the object Boston.
data(Boston)
# Read about the data set:
dim(Boston)
```
# b Make some pairwise scatterplots of the predictors (columns) in this data set. Describe your findings.

crim should be the response variable, which seems like have positive relationship with nox and rm. The plots is mass. We need to do some transformations to dig more pattern.
```{r }
pairs(Boston)
```

# c Are any of the predictors associated with per capita crime rate? If so, explain the relationship.

There are a significant positive relationship between crim and zn and rad 
There are a significant negtive relationship between crim and  nox, dis,black and medv.
```{r}
lm_cr <- lm(crim ~ . ,data = Boston)
summary(lm_cr)
```
# (d) Do any of the suburbs of Boston appear to have particularly high crime rates? Tax rates? Pupil-teacher ratios? Comment on the range of each predictor.
We can see that most suburbs have a crime rate at or close to zero, but some suburbs have very high crime freq more than 350.
Tax is polarized
Ptratio seems not have any huge outliers and has a smaller range.

```{r}
hist(Boston$crim, breaks = 50)
hist(Boston$tax, breaks = 50)
hist(Boston$ptratio, breaks = 50)
```
# (e) How many of the suburbs in this data set bound the Charles river?
There are 35 suburbs bound by the Charles river.
```{r}
table(Boston$chas)
```
# (f) What is the median pupil-teacher ratio among the towns in this data set?
the median pupil-teacher ratio is 19.05.
```{r}
median(Boston$ptratio)
```
# (g) Which suburb of Boston has lowest median value of owner-occupied homes? What are the values of the other predictors for that suburb, and how do those values compare to the overall ranges for those predictors? Comment on your findings.

There are two suburbs with the lowest median value of owner-occupied homes, observation 399 and 406.
We can see that both suburbs with the lowest medv and very similar other predictors. 
We draw boxplot or summary to compare to the overall ranges for those predictors. 
We can see there is great than 75% for crim, age, lstat, indus, nox, rad, tax, ptratio. Both suburbs are chas = 0 which meands they are not near the Charles river. And They have lower percentiles forzn, rm, dis. 

```{r}
Boston[Boston$medv == min(Boston$medv), ]
```
```{r}
summary(Boston)
boxplot( crim ~ . ,data = Boston)
```

# (h) In this data set, how many of the suburbs average more than seven rooms per dwelling? More than eight rooms per dwelling? Comment on the suburbs that average more than eight rooms per dwelling.

```{r}
sum(Boston$rm > 7)
sum(Boston$rm > 8)
```


## 1 Suppose you have following functions. Write an R function to each of them and then make plot for each one in a range between (≠10, 10) or their restricted range.
f1(x) = 2 + 3x^2 - x
f2(x)= 1/(B(2,3)), where 0<x<1,whereB(2,3)isabetefunction.

```{r 1.1}
x1 <- -10:10
y1 <- 2 + 3*x1^2 - x1
plot(y1~x1)
```
```{r 1.2}
x_beta <- seq(0, 1, by = 0.02) 
#y_beta = B(2,3) 
y_beta <- dbeta(x_beta, shape1 = 2, shape2 = 3) 
#y2 <- 1/y_beta * x_beta * (1-x_beta)^2
#plot(y2~x_beta)  
plot(y_beta)
```

###2. In this problem, 
you search the internet using “Auto-mpg dataset” to find an automobile mpg data. Most likely you would be able to find it in either at “kaggle”, or “UCI Machine Learning Repository.” Note that you do not use the original data.
```{r 2}
setwd("/Users/hxwh/Desktop")
autompg <- read.table("auto_mpg.data") # load data

names(autompg) <- c("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "car_name")
head(autompg,3)
```

## 2b Check the classes of your variables by using sapply command. What are the classes of horsepower, model_year and name?


# Answer: the classes of horsepower is factor, class of model_year is integer and class of name is factor.
```{r 2 b}
sapply(autompg,class)
```
## 2c From the original data, horsepower is supposed to be numeric. Do you see any problem? In R, any missing value is labeled as “NA”. Try to clean the data (actually the horsepower column) and replace any character to “NA"

# In this dataset horsepower is factor variable 
```{r 2 c}
#is.na(as.numeric(autompg$horsepower))
which(is.na(as.numeric(autompg$horsepower)))
x = as.numeric(as.character(autompg$horsepower))
```
## 2d Do a summary analysis of the data (numeric variables) by checking each variable’s range, extreme values, mean, median, standard deviation, etc. Check the correlations among the variables and plot pairwise graph between each two variables by using command pairs.


```{r 2 d}
# Check horsepower range, extreme values, mean, median, standard deviation
summary(autompg$x)
# Check mpg range, extreme values, mean, median, standard deviation
summary(autompg$mpg)
# Check displacement range, extreme values, mean, median, standard deviation
summary(autompg$displacement)
# Check weight range, extreme values, mean, median, standard deviation
summary(autompg$weight)
# Check acceleration range, extreme values, mean, median, standard deviation
summary(autompg$acceleration)

```
```{r check correlation}
num_data <- data.frame(x,autompg$mpg,autompg$displacement,autompg$weight,autompg$acceleration)
names(num_data)[1] <- "horsepower"
res <- cor(num_data)
round(res, 2)
```
```{r plot of correlations among variables }
pairs(num_data, pch = 19)
```
## 2e Create a two-variable data, with only acceleration and mpg in it. Make a scatter plot between them by using mpg as y-axis variable. Do you see strong correlation between the two variables? In addition, what is a correlation?


# Yes, there is strong correlation between these two variables. positive correlation.
```{r 2e}
data_two <- data.frame(autompg$mpg,autompg$acceleration)
plot(data_two$autompg.acceleration, data_two$autompg.mpg, main="Scatterplot Example", xlab="acceleration ", ylab="mpg ", pch=19)
```


## 2f Run a linear regression between the variables in part e) and use mpg as the response variable, acceleration as the predictor. What’s your conclusion for this analysis? In addition, add the regression line to the plot in part e).


# regression model is mpg_prediction = 4.9698 + 1.1912 * acceleration
# Intercept and acceleration are statistical sigmificant 
# Adjusted R-squared is equal to 0.1746 which is much less than 1 means this linear model maybe not fit very well. 
```{r 2f}
plot(autompg.mpg ~ autompg.acceleration, data = data_two, ylab = "mpg",
     xlab = "acceleration")
lmod = lm(autompg.mpg ~ autompg.acceleration, data = data_two)
abline(lmod, col="red")
summary(lmod)
```

## 2g Using the regression in part f), make a prediction of mpg for each acceleration values in the data. Draw a scatter plot between the original mpg and the predicted mpg. Comment.


# If prediction of mpg are equal to original mpg, the scatter points shoud distribute around the diagonal. But the plot below shows that part of points are above the line and others are belove the diagonal line, which means there are error between prediction and observation.
```{r 2g}
summary(lmod)
# prediction of mpg
mpg_pd = 4.9698 + 1.1912 * data_two$autompg.acceleration
#  scatter plot
# plot(lmod)
plot(data_two$autompg.mpg,mpg_pd, main="Scatterplot between original and predicted mpg.", xlab="original ", ylab="predicted ", xlim=c(0,50), ylim=c(0,50), pch=19)

abline(a=0,b=1, col="red")
```

## 2h MSE is an abbreviation for Mean Squared Error, which is the average of the squared dierences between the estimated and the truth value (or observed value). For the results in part g), treat the original mpg as true values, and predicted mpg as estimates. Find the MSE of this prediction.


# MSE = (1/n) * Σ(actual – prediction)2
# the MSE of this prediction is 50.17219
```{r 2h}
#calculate MSE based on model
mean(lmod$residuals^2)
# Calculate MSE from a list of Predicted and Actual Values
data <- data.frame(pred = predict(lmod), actual = data_two$autompg.mpg)
#head(data,3)
(MSE <- mean((data$actual - data$pred)^2))

```

## 2i The Locally Estimated Scatterplot Smoothing, or LOESS, is a moving regression to fit data more smoothly. Use the loess function in R to make a LOESS regression between acceleration and mpg. What is the MSE of the prediction in this case? Comment, including the results in part h). Add the LOESS regression line into the graph you drew for part h)


# MSE of the prediction is 47.67229
```{r 2i}

lmod_lo <- loess(autompg.mpg ~ autompg.acceleration, data = data_two)
#calculate MSE based on model
mean(lmod_lo$residuals^2)

plot(autompg.mpg ~ autompg.acceleration, data = data_two, ylab = "mpg", xlab = "acceleration")
lines(data_two$autompg.acceleration,lmod_lo$fitted,col="blue",lwd=3)
abline(lmod, col="red")



```

##2 j) Using summary to check the result of your LOESS regression in part i). The span, in the Control settings, is a smoothing parameter. Now try to run another (or more if you like) LOESS regression by adding span option in your loess command. Comment on the results.


# see below
```{r 2j}

summary(lmod_lo)

lmod_lo_span10 <- loess(autompg.mpg ~ autompg.acceleration, data = data_two, span = 0.11)
lmod_lo_span30 <- loess(autompg.mpg ~ autompg.acceleration, data = data_two, span = 0.3)
lmod_lo_span50 <- loess(autompg.mpg ~ autompg.acceleration, data = data_two, span = 0.5)
lmod_lo_span100 <- loess(autompg.mpg ~ autompg.acceleration, data = data_two, span = 1)
summary(lmod_lo_span10)
summary(lmod_lo_span30)
summary(lmod_lo_span50)

```
```{r plot with span}
plot(autompg.mpg ~ autompg.acceleration, data = data_two, ylab = "mpg",
     xlab = "acceleration")
lines(data_two$autompg.acceleration,lmod_lo_span10$fitted,col="blue",lwd=3)
lines(data_two$autompg.acceleration,lmod_lo_span30$fitted,col="green",lwd=3)
lines(data_two$autompg.acceleration,lmod_lo_span50$fitted,col="orange",lwd=3)
lines(data_two$autompg.acceleration,lmod_lo_span100$fitted,col="pink",lwd=3)
abline(lmod, col="red")
```
# I tried span =0.1, 0.3 and 0.5 and 1. Based on the plot above as the span increases, the smoothing of the curve also increases and the accuracy of the fitted curve also increasing.